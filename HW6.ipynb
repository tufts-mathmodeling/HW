{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOnszy8HzvAoLjfmDkdUKif",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tufts-mathmodeling/HW/blob/master/HW6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0_4wWg1m7i3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%config InlineBackend.figure_formats = ['svg']\n",
        "from random import sample\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits import mplot3d\n",
        "from numpy import linalg as LA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3q2oFc1nAXn",
        "colab_type": "text"
      },
      "source": [
        "# Math Modeling Homework 6 (Spring 2020)\n",
        "\n",
        "## Basics\n",
        "\n",
        "Here's some code that gives you eigen-data for the matrix $M=\\begin{bmatrix}2&1\\\\ 1&1\\end{bmatrix}$. Then we can iterate the matrix $M$, normalize the output, and study the long-term dynamics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqD4XRudovgy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "M = np.matrix([[2, 1], [1, 1]])\n",
        "evals, evecs = LA.eig(M)\n",
        "print('eigenvalues:',evals)\n",
        "print('corresponding eigenvectors are the columns:')\n",
        "print(evecs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwU6hIP-ozs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "M = np.matrix([[2, 1], [1, 1]])\n",
        "v= np.array([1,1])\n",
        "for n in range(1,11):\n",
        "    print(n,'th step, normalized:',M**n@v/LA.norm(M**n@v),'vector length:',LA.norm(M**n@v))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Z0xxaUOpNfb",
        "colab_type": "text"
      },
      "source": [
        "## Problem 1: Power Method and Markov Chains (8 points)\n",
        "\n",
        "(a) By entering several different $v$ vectors and experimenting with the number of iterates, describe the dynamics of $M^n\\cdot v$.  Can you find a vector that shrinks instead of expands?  Is that still true if you increase the range of powers you consider?  *Optional but recommended*: write code that plots the normalized iterates and include some pictures.\n",
        "\n",
        "*Warning for the \"shrinking\" part of the previous problem: unless you're extra careful, you'll eventually start to get rounding errors in python, so don't be too alarmed if weird things start happening when you're demanding lots of precision.*\n",
        "\n",
        "(b) Repeat a similar experiment with the iteration matrix $P$ from the stock market example in class.  Explain why this follows a different pattern of vector length than in the previous example.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWTmycQbq-mS",
        "colab_type": "text"
      },
      "source": [
        "## Monte Carlo Everything\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmIvEU9Erkdc",
        "colab_type": "text"
      },
      "source": [
        "## Problem 2: Scrabble tiles (4 points)\n",
        "\n",
        "Here are all the letters in a Scrabble set, with frequency and value.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMORKDXnrvXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "letters = {\n",
        "    ' ': (2, 0),\n",
        "    'a': (9, 1),\n",
        "    'b': (2, 3),\n",
        "    'c': (2, 3),\n",
        "    'd': (4, 2),\n",
        "    'e': (12, 1),\n",
        "    'f': (2, 4),\n",
        "    'g': (3, 2),\n",
        "    'h': (2, 4),\n",
        "    'i': (9, 1),\n",
        "    'j': (1, 8),\n",
        "    'k': (1, 5),\n",
        "    'l': (4, 1),\n",
        "    'm': (2, 3),\n",
        "    'n': (6, 1),\n",
        "    'o': (8, 1),\n",
        "    'p': (2, 3),\n",
        "    'q': (1, 10),\n",
        "    'r': (6, 1),\n",
        "    's': (4, 1),\n",
        "    't': (6, 1),\n",
        "    'u': (4, 1),\n",
        "    'v': (2, 4),\n",
        "    'w': (2, 4),\n",
        "    'x': (1, 8),\n",
        "    'y': (2, 4),\n",
        "    'z': (1, 10)\n",
        "}\n",
        "letter_freq = {letter: v[0] for letter, v in letters.items()}\n",
        "letter_score = {letter: v[1] for letter, v in letters.items()}\n",
        "letter_pool = []\n",
        "for letter, freq in letter_freq.items():\n",
        "    letter_pool += [letter] * freq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KA6lIbkgrz5n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_trials = 1000\n",
        "expected_score = sum(letter_freq[letter] * score\n",
        "                     for letter, score in letter_score.items()) / len(letter_pool)\n",
        "avg_scores = []\n",
        "total_score = 0\n",
        "for trial in range(1, n_trials + 1):\n",
        "    total_score += letter_score[sample(letter_pool, 1)[0]]\n",
        "    avg_scores.append(total_score / trial)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQROvEGnr3Qv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.xlabel('Trial')\n",
        "plt.ylabel('Average score')\n",
        "plt.title('Expected Scrabble tile score')\n",
        "plt.plot([0, n_trials], [expected_score, expected_score],\n",
        "         color='orange',\n",
        "         label='Expected score (exact)')\n",
        "plt.ylim(expected_score - 1, expected_score + 1)\n",
        "plt.xlim(0, n_trials)\n",
        "plt.plot(avg_scores, label='Expected score (estimate)')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXborRHzr5bf",
        "colab_type": "text"
      },
      "source": [
        "Explain what's happening in the plotting code above and why.  Report how much you have to extend the trials to get accuracy within .1, .01, .001, .0001.  Re-run a few times at each experiment size to get a sense of how much things are stable or changeable due to stochasticity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HRCWPYPsq2R",
        "colab_type": "text"
      },
      "source": [
        "## Problem 3: Distances and volumes (16 points)\n",
        "The simulation above is not deepâ€”we can just calculate the expected point value of a Scrabble tile directly, so why bother with Monte Carlo sampling? Indeed, Monte Carlo sampling is most useful for problems that don't have an easy (or known) closed-form solution. Consider the problem of determining the expected distance between two points in a cube. This problem _does_ have a closed-form solution, expressed as the big ol' integral\n",
        "\n",
        "$$\\int_{0}^{1} \\int_{0}^{1} \\int_{0}^{1} \\int_{0}^{1} \\int_{0}^{1} \\int_{0}^{1} \\sqrt{(x_1 - y_1)^2 + (x_2 - y_2)^2 + (x_3 - y_3)^2} \\ dx_1 dx_2 dx_3 dy_1 dy_2 dy_3$$\n",
        "\n",
        "which evaluates to\n",
        "\n",
        "$$\\frac{4 + 17 \\sqrt{2} - 6 \\sqrt{3} + 21 \\log(1 + \\sqrt{2}) + 42 \\log(2 + \\sqrt{3}) - 7\\pi}{105} \\approx 0.6617 $$\n",
        "\n",
        "We can avoid dealing with the integrals by using the Monte Carlo method to estimate the answer. Rather than sampling individual Scrabble tiles, we'll sample _pairs_ of points in the cube. First let's plot some pairs to get an idea of the distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck8c0Oq3s6Qx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_pairs_plot = 50\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "for _ in range(n_pairs_plot):\n",
        "    # We uniformly sample endpoints from (0, 0, 0)..(1, 1, 1).\n",
        "    p1 = np.random.random(3)\n",
        "    p2 = np.random.random(3)\n",
        "    pair = np.array([p1, p2]).T\n",
        "    ax.scatter(*pair, color='green')\n",
        "    ax.plot(*pair, color='red')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aiy-e06NtH5a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_pairs_monte = 1000\n",
        "total_distance = 0\n",
        "avg_distances = []\n",
        "distances = []\n",
        "expected_distance = (4 + 17 * np.sqrt(2) - 6 * np.sqrt(3) +\n",
        "                     21 * np.log(1 + np.sqrt(2)) + 42 * np.log(2 + np.sqrt(3)) -\n",
        "                     7 * np.pi) / 105\n",
        "print('exact distance expectation is {:.3f}'.format(expected_distance))\n",
        "for trial in range(1, n_pairs_monte + 1):\n",
        "    # We uniformly sample endpoints from (0, 0, 0)..(1, 1, 1).\n",
        "    p1 = np.random.random(3)\n",
        "    p2 = np.random.random(3)\n",
        "    pair_dist = np.sqrt(np.sum(np.power(p1 - p2, 2)))\n",
        "    total_distance += pair_dist\n",
        "    distances.append(pair_dist)\n",
        "    avg_distances.append(total_distance / trial)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjgMhlOmtQNZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(avg_distances, label='Expected distance (estimate)')\n",
        "plt.plot([0, n_pairs_monte], [expected_distance, expected_distance], label='Expected distance (exact)')\n",
        "plt.xlabel('Trial')\n",
        "plt.ylabel('Distance')\n",
        "plt.xlim(0, n_pairs_monte)\n",
        "plt.ylim(expected_distance - 0.2, expected_distance + 0.2)\n",
        "plt.title('Distance between pairs in the unit cube')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GHHZ8e5tScb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(distances)\n",
        "plt.axvline(expected_distance,color='red')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBfU-IzQtWQt",
        "colab_type": "text"
      },
      "source": [
        "(a) Recall from class that the \"cube\" in any $\\mathbb R^n$ can be modeled by letting each of the $n$ variables range over $[0,1]$.  Use Monte Carlo methods to estimate the average distance between points in the cube in dimension 2 (that's a square!), 4, and 5.  \n",
        "\n",
        "Now let's look at some area and volume estimates.\n",
        "\n",
        "The method below illustrates visually how to estimate the area of the circle: you drop random points and count how many are in it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFXpCpWJu19J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = np.linspace(0, 1, 100)\n",
        "quarter_circle = np.sqrt(1 - x**2)\n",
        "fig,ax = plt.subplots()\n",
        "ax.plot(x, quarter_circle)\n",
        "ax.scatter(np.random.random(100), np.random.random(100), color='red')\n",
        "ax.set_aspect('equal')\n",
        "plt.title('Area under the unit circle')\n",
        "plt.xlim(0, 1)\n",
        "plt.ylim(0, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hSDEL2Xu70c",
        "colab_type": "text"
      },
      "source": [
        "(b) Recall that the \"unit ball\" in any $\\mathbb R^n$ is just the points $(x_1,\\dots,x_n)$ satisfying $x_1^2+\\dots+x_n^2=1$.  Estimate the volumes of the unit balls in dimension 2,3,4,5 by estimating what share of random points with coordinates $-1\\le x_i \\le 1$ are in them.\n",
        "\n",
        "(c) Draw yourself a unit circle and GUESS what the average distance between points inside it will be.  Now use Monte Carlo to estimate the actual answer.  Repeat for dimension 3,4,5.  Discuss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rj0U8gqlvd25",
        "colab_type": "text"
      },
      "source": [
        "## Problem 3: Buffon's needle (4 points)\n",
        "\n",
        "In class we're doing the example of Buffon's needle, where you drop a needle on a floor and see if it hits the seams.  Fully explain how the code below works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOGvFVihvn2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_needle(x, y, theta, size):\n",
        "    x_end = x + size * np.cos(theta)\n",
        "    y_end = y + size * np.sin(theta)\n",
        "    plt.plot([x, x_end], [y, y_end], markersize=2)\n",
        "\n",
        "n_lanes = 5\n",
        "needle_size = 1\n",
        "for idx in range(n_lanes + 1):\n",
        "    plt.plot([idx, idx], [-2 * needle_size, 2 * needle_size],color='black')\n",
        "plt.ylim(-2 * needle_size, 2 * needle_size)\n",
        "plt.xlim(-0.5, n_lanes + 0.5)\n",
        "for _ in range(20):\n",
        "    plot_needle(n_lanes * np.random.random(), 2 * np.random.random() - 1, 2 * np.pi * np.random.random(), needle_size)\n",
        "plt.title(\"Buffon's needle\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlsAhGYEvx-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "buffon_est = []\n",
        "hits = 0\n",
        "for trial in range(1, 1001):\n",
        "    x = np.random.random()\n",
        "    theta = 2 * np.pi * np.random.random()\n",
        "    x_end = x + np.cos(theta)\n",
        "    if min(x, x_end) % 1 > max(x, x_end) % 1:\n",
        "        hits += 1\n",
        "    if hits > 0:\n",
        "        p = hits / trial\n",
        "        buffon_est.append(2 / p)\n",
        "plt.title(\"Value\")\n",
        "plt.xlabel('Trial')\n",
        "plt.plot(buffon_est)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}