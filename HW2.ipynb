{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    },
    "colab": {
      "name": "HW2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tufts-mathmodeling/HW/blob/master/HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KJ31X19YMkJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import cvxpy as cp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqjG-gmpsz38",
        "colab_type": "text"
      },
      "source": [
        "# Math Modeling Homework 2 (Spring 2020)\n",
        "\n",
        "# Part I: Root finders and finite differences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doiiVXkwsz3-",
        "colab_type": "text"
      },
      "source": [
        "### Newton's method\n",
        "As described in class, Newton's method gives an approximation $x_k$ to $f(x)$ using the tangent line at the previous iterate, $x_{k-1}$. Convergence is guaranteed if the initial guess, $x_0$, is close enough to the root, and if $f$ is continuously differentiable near the root. Both $f(x)$ and $f'(x)$ are required for implementation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-m3FbVAQsz4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def newton(f, df, x0, max_steps=100, tol=1e-10):\n",
        "    \"\"\"Computes iterates of Newton's method for solving f(x) = 0.\n",
        "    \n",
        "    :param f: The function to find a root for.\n",
        "    :param df: The derivative of the function.\n",
        "    :param x0: The initial guess.\n",
        "    :return: The final iterate and the total number of iterations needed.\n",
        "    \"\"\"\n",
        "    x = x0\n",
        "    for iteration in range(max_steps):\n",
        "        if abs(f(x)) <= tol:\n",
        "            return x, iteration\n",
        "        x -= f(x) / df(x)\n",
        "    return x, max_steps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35C5RKd_sz4H",
        "colab_type": "text"
      },
      "source": [
        "### Bisection method\n",
        "The bisection algorithm assumes that you know two points, $x_\\ell$ and $x_r$, for which $f(x_\\ell)$ and $f(x_r)$ have opposite signs.  For continuous $f$, this implies there is a zero between $x_\\ell$ and $x_r$. **(Why?)** To find it, the algorithm iteratively divides the interval from $x_\\ell$ to $x_r$ into two parts by examining the sign of $f((x_\\ell+x_r)/2)$ and discarding the endpoint of the same sign.  No assumption on $f$ is made aside from continuity, and convergence is always guaranteed.  Only $f(x)$ is needed for implementation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9CaVgcasz4I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bisection(f, x_left, x_right, max_steps=100, tol=1e-10):\n",
        "    \"\"\"Computes iterates of the bisection method for solving f(x) = 0.\n",
        "    \n",
        "    The signs of f(x_left) and f(x_right) must differ.\n",
        "    \n",
        "    :param f: The function to find a root for.\n",
        "    :param x_left: A guess to the left of the root.\n",
        "    :param x_right: A guess to the right of the root.\n",
        "    \"\"\"\n",
        "    f_left = f(x_left)\n",
        "    f_right = f(x_right)\n",
        "    assert (f_left * f_right).real <= 0 # Signs of initial guesses must differ.\n",
        "    \n",
        "    x_middle = (x_left + x_right) / 2\n",
        "    f_middle = f(x_middle)\n",
        "    for iteration in range(max_steps):\n",
        "        if abs(f_middle) <= tol:\n",
        "            return x_middle, iteration\n",
        "        # Narrow the search.\n",
        "        if (f_left * f_middle).real > 0:\n",
        "            # The left guess and the middle guess have the same sign.\n",
        "            # Replace the left guess with the middle guess.\n",
        "            x_left = x_middle\n",
        "            f_left = f_middle\n",
        "        else:\n",
        "            # The right guess and the middle guess have the same sign.\n",
        "            # Replace the right guess with the middle guess.\n",
        "            x_right = x_middle\n",
        "            f_right = f_middle\n",
        "        # Compute the new middle point.\n",
        "        x_middle = (x_left + x_right) / 2\n",
        "        f_middle = f(x_middle)\n",
        "    return x_middle, max_steps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me9DovEysz4P",
        "colab_type": "text"
      },
      "source": [
        "### Secant method\n",
        "As briefly mentioned in class, the secant method gives an approximation $x_k$ to $f(x)$ by the secant line between two previous points, $x_{k-1}$ and $x_{k-2}$.  Convergence is guaranteed if the initial guesses, $x_0$ and $x_1$ are close enough to the root, and if $f$ is twice continuously differentiable near the root with nonzero first derivative at the root.  Despite these weaker theoretical guarantees of convergence, an advantage is that only $f(x)$ is needed for implementation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L8GiHHwsz4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def secant(f, x0, x1, max_steps=100, tol=1e-10):\n",
        "    \"\"\"Computes iterates of the secant method for solving f(x) = 0.\n",
        "    \n",
        "    :param f: The function to find a root for.\n",
        "    :param x0: A first initial guess.\n",
        "    :param x1: A second initial guess.\n",
        "    :return: The final iterate and the total number of iterations needed.\n",
        "    \"\"\"\n",
        "    x_old = x0\n",
        "    x_new = x1\n",
        "    f_old = f(x_old)\n",
        "    f_new = f(x_new)\n",
        "    for iteration in range(max_steps):\n",
        "        if abs(f(x_new)) <= tol:\n",
        "            return x_new, iteration\n",
        "        x_next = x_new - (f_new * (x_new - x_old) / (f_new - f_old))\n",
        "        x_old = x_new\n",
        "        f_old = f_new\n",
        "        x_new = x_next\n",
        "        f_new = f(x_next)\n",
        "    return x_new, max_steps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIheOooxsz4X",
        "colab_type": "text"
      },
      "source": [
        "### Halley's method\n",
        "Halley's method (same Edmond Halley of Halley's comet) approximates $f(x)$ by a ratio of linear functions determined by the previous iterate.  The update formula is given by\n",
        "\n",
        "\\begin{equation}\n",
        "x_{k} = x_{k-1} -\n",
        "\\frac{2f(x_{k-1})f'(x_{k-1})}{2\\left(f'(x_{k-1})\\right)^2 - f(x_{k-1})f''(x_{k-1})}.\n",
        "\\end{equation}\n",
        "\n",
        "Convergence is guaranteed if the initial guess, $x_0$, is close enough to the root, and if $f$ is three times continuously differentiable near the root.  All of $f(x)$, $f'(x)$, and $f''(x)$ are required for implementation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwfB8jmqsz4e",
        "colab_type": "text"
      },
      "source": [
        "## Python concept we're using: passing functions to functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "180GeRZTsz4g",
        "colab_type": "text"
      },
      "source": [
        "All four root-finding functions take functions as arguments. This is a common pattern used in optimization libraries [such as scipy.optimize](https://docs.scipy.org/doc/scipy/reference/optimize.html). In the example below, we define Python functions that correspond to the polynomial $f(x) = x^2 - x - 2$ and its first and second derivative. We then pass these functions to the root-finding functions and compare the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Osx9V6Gtsz4j",
        "colab_type": "code",
        "outputId": "23af5b78-3f4f-4399-9fff-c294616c36ef",
        "colab": {}
      },
      "source": [
        "def quadratic_f(x):\n",
        "    return x**2 - x - 2\n",
        "\n",
        "def quadratic_df(x):\n",
        "    return (2 * x) - 1 # first derivative of f(x) -- manually computed\n",
        "\n",
        "def quadratic_ddf(x):\n",
        "    return 2 # second derivative of f(x) -- manually computed\n",
        "\n",
        "root_bisect, iter_bisect = bisection(quadratic_f, -5, 0)\n",
        "root_newton, iter_newton = newton(quadratic_f, quadratic_df, 0)\n",
        "root_secant, iter_secant = secant(quadratic_f, -5, 0)\n",
        "root_halley, iter_halley = halley(quadratic_f, quadratic_df, quadratic_ddf, 0)\n",
        "print(f'The bisection method took {iter_bisect} iterations to find the root x={root_bisect}.')\n",
        "print(f'The Newton method took {iter_newton} iterations to find the root x={root_newton}.')\n",
        "print(f'The secant method took {iter_secant} iterations to find the root x={root_secant}.')\n",
        "print(f'The Halley method took {iter_halley} iterations to find the root x={root_halley}.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The bisection method took 35 iterations to find the root x=-0.9999999999854481.\n",
            "The Newton method took 6 iterations to find the root x=-1.0.\n",
            "The secant method took 8 iterations to find the root x=-1.0000000000000013.\n",
            "The Halley method took 4 iterations to find the root x=-1.0.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAxUdfZWsz40",
        "colab_type": "text"
      },
      "source": [
        "Sometimes, it is cumbersome to define functions in the way illustrated above. Rather than using the `def` keyword, we can use [one-line _lambda expressions_](https://docs.python.org/3/tutorial/controlflow.html#lambda-expressions) to create anonymous functions—that is, functions without an explicit name. Here's how we might rewrite the root-finding problem above as a series of lambda expressions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7Ybio_Esz42",
        "colab_type": "code",
        "outputId": "cf1b8cb5-9ccc-4ced-945f-d3f6f22dbd12",
        "colab": {}
      },
      "source": [
        "root_halley, iter_halley = halley(lambda x: x**2 - x - 2,\n",
        "                                  lambda x: (2 * x) - 1,\n",
        "                                  lambda x: 2,\n",
        "                                  0)\n",
        "print(f'The Halley method took {root_halley} iterations to find the root x={iter_halley}.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Halley method took 11 iterations to find the root x=0.9999943549689424.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WnoFzDjsz49",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Now your actual homework problems...**\n",
        "\n",
        "### Problem 1: Microprocessor division with Newton's method (8 points)\n",
        "One of the uses of Newton's method is in implementing division on microprocessors, where only addition and multiplication are available as primitive operations.  To compute $x=\\frac{a}{b}$, first the root of $f(x) = \\frac{1}{x} - b$ is found using Newton's method, then the fraction is computed with one last multiplication by $a$.  \n",
        "\n",
        "**(i)** Find the Newton iteration needed to solve $f(x)=0$ and explain why it is well-suited to this purpose.  *(Note: We are trying to approximate division, so we shouldn't actually use it...)*\n",
        "\n",
        "**(ii)** Explain why Halley's method is not well-suited to this purpose.\n",
        "\n",
        "**(iii)** Apply Newton's method to computing $1/b$, where $b$ is (a) the last 3 digits of your student ID number; and (b) the area code of your phone number. For these experiments, report the iterates until the approximation is consistent with the last iterate to 10 digits (you will need to modify the given code in order to do so). For instance, `newton_division(1, 3, 0.01)` should print something like:\n",
        "```\n",
        "Iteration 0: 1/b = 0.01\n",
        "Iteration 1: 1/b = 0.0197\n",
        "Iteration 2: 1/b = 0.038235729999999996\n",
        "Iteration 3: 1/b = 0.07208554685410129\n",
        "Iteration 4: 1/b = 0.1285821155124381\n",
        "Iteration 5: 1/b = 0.20756414973591425\n",
        "Iteration 6: 1/b = 0.2858796707050494\n",
        "Iteration 7: 1/b = 0.3265777830428163\n",
        "Iteration 8: 1/b = 0.3331964209541502\n",
        "Iteration 9: 1/b = 0.33333327709833466\n",
        "Iteration 10: 1/b = 0.3333333333333238\n",
        "Iteration 11: 1/b = 0.3333333333333333\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hy32FzMcsz5i",
        "colab_type": "text"
      },
      "source": [
        "### Problem 2: Square roots with Newton's method (4 points)\n",
        "\n",
        "Another use for Newton's method and other rootfinding approaches is for computing square roots, by solving for zeros of $f(x) = x^2-a$.  Apply all of the above methods to computing $\\sqrt{a}$ where $a$ is (a) the last 3 digits of your student number and (b) the area code of your phone number. Explain how you choose good initial guesses, and report the number of iterations needed for convergence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "template"
        ],
        "id": "jh9mQsl2sz5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def newton_sqrt(a, x0):\n",
        "    \"\"\"Finds the square root of a number using Newton's method.\n",
        "    \n",
        "    Your code should pass a function and its derivative to the\n",
        "    newton() function and return the square root of `a` and the\n",
        "    number of iterates required.\n",
        "    \n",
        "    :param a: The number to find a square root of.\n",
        "    :param x0: An initial guess of the square root.\n",
        "    \"\"\"\n",
        "    # TODO: Your code here!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SY1Yspywsz5u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unit tests for newton_division().\n",
        "# Use these to make sure your implementation is behaving properly.\n",
        "sqrt_tol = 1e-5\n",
        "for a in (0, 0.001, 0.01, 0.1, 1, 10, 100, 1000):\n",
        "    sqrt_a, _ = newton_sqrt(a, 1)\n",
        "    assert abs(sqrt_a - np.sqrt(a)) <= sqrt_tol"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "template"
        ],
        "id": "Q7lJ4_ADsz5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Your code here!\n",
        "# Use newton_sqrt() to compute the square root of the last 3 digits\n",
        "# of your student number and the area code of your phone number.\n",
        "# Print the square roots and the number of iterations necessary to find them."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHrlmha9sz53",
        "colab_type": "text"
      },
      "source": [
        "### Problem 3: Comparison of methods (4 points)\n",
        "In this problem, we'll look at performance of various methods for functions, with and without the conditions needed for the theoretical guarantee of convergence.  Consider the 3 functions\n",
        " \n",
        "\\begin{align*}\n",
        "f_1(x) & = x^3 \\\\\n",
        "f_2(x) & = x^3 + 2x \\\\\n",
        "f_3(x) & = x^3 + 2x^{5/4}\n",
        "\\end{align*}\n",
        "\n",
        "Report on the iteration counts for each algorithm for each function to find the root at $x=0$ for consistent initial guesses (be sure to avoid cases where the algorithms get \"lucky\" and find the solution $x=0$ at their first step).  You will be graded on your discussion of what you observe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "template"
        ],
        "id": "3W1mJ6-nsz54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = ['x³', 'x³ + 2x', 'x³ + 2x⁵⁄⁴']\n",
        "\n",
        "functions = [\n",
        "    lambda x: x**3,\n",
        "    lambda x: x**3 + (2 * x),\n",
        "    lambda x: x**3 + (2 * x**1.25)\n",
        "]\n",
        "\n",
        "df_funcs = [\n",
        "    # TODO: Your code here!\n",
        "    # Write lambda expressions for the first derivatives\n",
        "    # of the three functions above.\n",
        "]\n",
        "\n",
        "ddf_funcs = [\n",
        "    # TODO: Your code here!\n",
        "    # Write lambda expressions for the second derivatives\n",
        "    # of the three functions above.\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-R8tXSKxxv9",
        "colab_type": "text"
      },
      "source": [
        "Now we just report the comparisons.  Experiment with the parameters here and make sure you understand the role they play."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "solution"
        ],
        "id": "KnQJQAgMsz6E",
        "colab_type": "code",
        "outputId": "785814a9-e681-4be4-f185-658f7695702e",
        "colab": {}
      },
      "source": [
        "for label, f, df, ddf in zip(labels, functions, df_funcs, ddf_funcs):\n",
        "    print('---', label, '---')\n",
        "    root_bisect, iter_bisect = bisection(f, -2, 5)\n",
        "    root_newton, iter_newton = newton(f, df, 5)\n",
        "    root_secant, iter_secant = secant(f, -2, 5)\n",
        "    root_halley, iter_halley = halley(f, df, ddf, 5)\n",
        "    print(f'Bisect:\\t{iter_bisect} iterations, x={root_bisect}')\n",
        "    print(f'Newton:\\t{iter_newton} iterations, x={root_newton}')\n",
        "    print(f'Secant:\\t{iter_secant} iterations, x={root_secant}')\n",
        "    print(f'Halley:\\t{iter_halley} iterations, x={root_halley}')\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- x³ ---\n",
            "Bisect:\t12 iterations, x=0.0003662109375\n",
            "Newton:\t23 iterations, x=0.0004455239404766183\n",
            "Secant:\t31 iterations, x=-0.0003789623402101401\n",
            "Halley:\t14 iterations, x=0.00030517578125\n",
            "\n",
            "--- x³ + 2x ---\n",
            "Bisect:\t34 iterations, x=-2.9103830456733704e-11\n",
            "Newton:\t8 iterations, x=0.0\n",
            "Secant:\t8 iterations, x=-1.938464878150942e-11\n",
            "Halley:\t5 iterations, x=3.324604317973129e-20\n",
            "\n",
            "--- x³ + 2x⁵⁄⁴ ---\n",
            "Bisect:\t28 iterations, x=-1.862645149230957e-09\n",
            "Newton:\t16 iterations, x=4.459017656768588e-09\n",
            "Secant:\t21 iterations, x=(-9.414029569228546e-10+2.1845973164009137e-09j)\n",
            "Halley:\t11 iterations, x=3.0392007280703785e-09\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXxzC-M2YMkU",
        "colab_type": "text"
      },
      "source": [
        "## Part 2: Linear programming\n",
        "In this part of the HW, we will use the [CVXPY](https://www.cvxpy.org/index.html) convex optimization package to solve linear programs. The basic syntax of CVXPY maps nicely to informal ways of writing linear programs. For instance, this linear program in two variables\n",
        "\n",
        "\n",
        "\\begin{align*}\n",
        "\\text{minimize  }2x + 3y & \\\\\n",
        "\\text{subject to } x + y &\\geq 1 \\\\\n",
        "y-x &\\leq 3 \\\\\n",
        "2x+y &\\leq 9 \\\\\n",
        "x-y &\\leq 3 \\\\\n",
        "x & \\geq 0 \\\\\n",
        "y & \\geq 0\n",
        "\\end{align*}\n",
        "\n",
        "can be expressed by just listing these inequalities as:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dDrzofJYMkX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = cp.Variable()\n",
        "y = cp.Variable()\n",
        "objective = cp.Minimize((2 * x) + (3 * y))\n",
        "constraints = [\n",
        "    x + y >= 1,\n",
        "    y - x <= 3,\n",
        "    (2 * x) + y <= 9,\n",
        "    x - y <= 3,\n",
        "    x >= 0,\n",
        "    y >= 0\n",
        "]\n",
        "prob = cp.Problem(objective, constraints=constraints)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ypvKgdzYMkb",
        "colab_type": "text"
      },
      "source": [
        "We'll call this the **list form** of a linear program.  We can use the `solve()` method to solve the program. A solver used internally by CVXPY [(learn more)](https://www.cvxpy.org/tutorial/advanced/index.html#choosing-a-solver) finds the optimal values for $x$ and $y$ with respect to the objective and the six constraints. The `solve()` method returns the minimum value of the objective function as a convenience.\n",
        "\n",
        "We'll use [floating point](https://en.wikipedia.org/wiki/Floating-point_arithmetic) numbers and specify a number of decimal places we want.  For instance, \"{0:.4f}\".format(0.1234567890) would return 0.1235 while \"{0:.3f}\".format(0.1234567890) would return 0.123."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvlGoUIMczub",
        "colab_type": "code",
        "outputId": "0ffc78e0-049d-4ca7-985c-b48f6435955b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"{:.3f}\".format(0.1234567890)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.123'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBaArWytYMkc",
        "colab_type": "code",
        "outputId": "27971f6d-8ea2-4839-cd89-7fdc87404b33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "list_solution = prob.solve()\n",
        "print('Optimal value: {:.4f}'.format(list_solution))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimal value: 2.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctMC_TxEYMkf",
        "colab_type": "text"
      },
      "source": [
        "We can also retrieve the values of $x$ and $y$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0y5e-3LYMkh",
        "colab_type": "code",
        "outputId": "aa32253c-b21d-4359-aa7c-31f069145f6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('x: {:.4f}, y: {:.4f}'.format(x.value, y.value))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x: 1.0000, y: 0.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1oJ3OGUYMkm",
        "colab_type": "text"
      },
      "source": [
        "### Matrix form\n",
        "\n",
        "It is often convenient to express linear programs in a condensed, canonical form, and matrices are convenient for that. Rather than dealing with a set of scalar variables, we can express all variables in the problem as a vector $\\mathbf{x}$. Likewise, we can store the coefficients of the constraints in a matrix $A$ and a vector $\\mathbf{b}$ and the coefficients of the objective in a vector $\\mathbf{c}$.\n",
        "\n",
        "\n",
        "\\begin{align*}\n",
        "\\text{minimize  } \\mathbf{c}^T \\mathbf{x} & \\\\\n",
        "\\text{subject to } A\\mathbf{x} \\leq \\mathbf{b} \\\\\n",
        "\\mathbf{x} \\geq 0\n",
        "\\end{align*}\n",
        "\n",
        "Let's write the linear program above in this form. First, we'll rewrite the constraints to be consistent with the $A\\mathbf{x} \\leq \\mathbf{b}$ constraint.\n",
        "\n",
        "\\begin{align*}\n",
        "\\text{minimize  }2x + 3y & \\\\\n",
        "\\text{subject to } -x - y &\\leq -1 \\\\\n",
        "-x + y &\\leq 3 \\\\\n",
        "2x+y &\\leq 9 \\\\\n",
        "x-y &\\leq 3 \\\\\n",
        "x &\\geq 0 \\\\\n",
        "y &\\geq 0\n",
        "\\end{align*}\n",
        "\n",
        "Let $\\mathbf{x} = \\begin{bmatrix} x & y \\end{bmatrix}$. We can translate the linear program by reading off coefficients:\n",
        "\n",
        "\\begin{align*}\n",
        "A = \\begin{bmatrix}\n",
        "-1 & -1 \\\\\n",
        "-1 & 1 \\\\\n",
        "2 & 1 \\\\\n",
        "1 & -1 \n",
        "\\end{bmatrix} &&\n",
        "\\mathbf{b} = \\begin{bmatrix} -1 \\\\ 3 \\\\ 9 \\\\ 3  \\end{bmatrix}  &&\n",
        "\\mathbf{c} = \\begin{bmatrix} 2 \\\\ 3 \\end{bmatrix} \n",
        "\\end{align*}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RenAfZKjYMkn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A = np.array([\n",
        "    [-1, -1],\n",
        "    [-1, 1],\n",
        "    [2, 1],\n",
        "    [1, -1]\n",
        "])\n",
        "b = np.array([-1, 3, 9, 3])\n",
        "c = np.array([2, 3])\n",
        "\n",
        "# We previously defined two scalar (one-dimensional) variables x and y.\n",
        "# Here we define a two-dimensional vector x, which we call x_vec in our code\n",
        "# to avoid confusion.\n",
        "x_vec = cp.Variable(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAxHansFYMkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "matrix_prob = cp.Problem(cp.Minimize(cp.sum(c.T @ x_vec)),\n",
        "                            constraints=[A@x_vec <= b, x_vec >= 0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o92RLNecYMkx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "matrix_solution = matrix_prob.solve()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBVOREFpYMk2",
        "colab_type": "text"
      },
      "source": [
        "We can verify that the minimum value of the objective function is the same as above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukQcsJiHYMk4",
        "colab_type": "code",
        "outputId": "4745626e-dee1-4b8b-ce9a-fc8fd29e29b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Optimal value (list form): {:.4f}'.format(two_var_solution))\n",
        "print('Optimal value (matrix form):    {:.4f}'.format(matrix_solution))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimal value (list form): 2.0000\n",
            "Optimal value (matrix form):    2.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqK0rD60YMlA",
        "colab_type": "text"
      },
      "source": [
        "Furthermore, the values of $\\mathbf{x}$ correspond with the values of $x$ and $y$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkUJ5HssYMlD",
        "colab_type": "code",
        "outputId": "febfe94d-9b7f-4dec-db8e-627cbf1199dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('x (list) is {:.4f}  and x[0] (matrix) is {:.4f}'.format(x.value, x_vec.value[0]))\n",
        "print('y (list) is {:.4f} and x[1] (matrix) is {:.4f}'.format(y.value, x_vec.value[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x (list) is 1.0000  and x[0] (matrix) is 1.0000\n",
            "y (list) is 0.0000 and x[1] (matrix) is -0.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01FL4FeuYMlN",
        "colab_type": "text"
      },
      "source": [
        "## Problem 4: a diet problem (8 points)\n",
        "Mackenzie, like a typical graduate student, wants to spend as little money as possible on food.  Somewhat less typically, she takes care to be sure she is still eating enough to hit her nutrition requriements:  calories (2,000 kcal), protein (55 g), and calcium (800 mg). Her local grocery store stocks six staple foods. The table below gives the nutrients and cost per serving of each food.\n",
        "\n",
        "|Food|Energy (kcal)|Protein (g)|Calcium (mg)|Price (cents)|\n",
        "|----|-------------|-----------|------------|-------------|\n",
        "|Oatmeal|110|4|2|3|\n",
        "|Chicken|205|32|12|24|\n",
        "|Eggs|160|13|54|13|\n",
        "|Milk|160|8|285|9|\n",
        "|Cherry pie|420|4|22|20|\n",
        "|Pork and beans|260|14|80|19|\n",
        "\n",
        "Note that ten servings of pork and beans per day meets her nutritional requirements, but not even a grad student can eat like that! She decides to limit the number of servings per day she consumes for each food:\n",
        "\n",
        "|Food|Max. servings|\n",
        "|----|-------------|\n",
        "|Oatmeal|4|\n",
        "|Chicken|3|\n",
        "|Eggs|2|\n",
        "|Milk|8|\n",
        "|Cherry pie|2|\n",
        "|Pork and beans|2|\n",
        "\n",
        "**Your task is to formulate and solve a linear program in the canonical form shown above to find the cheapest diet subject to these constraints.** The solution vector $\\mathbf{x} \\in \\mathbb{R}^6$ should be ordered to correspond to this table—$\\mathbf{x}_1$ servings of oatmeal, $\\mathbf{x}_2$ servings of chicken, and so on. Report the values of $A$, $\\mathbf{b}$, and $\\mathbf{c}$ (you may find [the `\\bmatrix` command](https://www.overleaf.com/learn/latex/Matrices) helpful in LaTeX when you're writing it up). Use CVXPY to solve the linear program; report the minimum cost (in cents) and the corresponding value of $\\mathbf{x}$. Fractional servings are allowed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFbv6-d6l9Hg",
        "colab_type": "text"
      },
      "source": [
        "## Problem 5: Exploring your diet solution (4 points)\n",
        "\n",
        "Which constraints are extremized in the optimal solution?  \n",
        "\n",
        "Relax one of those constraints by 1% and report by what percent that changed the optimum price.\n",
        "\n",
        "Can Mackenzie find a feasible diet consisting of *only* eggs and cherry pie?  Equivalently, this asks whether the Eggs/CherryPie plane intersects the feasible polyhedron.\n",
        "\n",
        "Report on any other observations that you can make by considering the geometry of the solution."
      ]
    }
  ]
}